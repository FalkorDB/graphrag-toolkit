{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40dfbd7",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9b60c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you haven't already, install the toolkit and dependencies using the [Setup](./00-Setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d08c74",
   "metadata": {},
   "source": [
    "### TraversalBasedRetriever\n",
    "\n",
    "See [TraversalBasedRetriever](https://github.com/awslabs/graphrag-toolkit/blob/main/docs/lexical-graph/querying.md#traversalbasedretriever)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check GPU support on Ubuntu 24.04 LTS",
   "id": "9bec686fd2672567"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:03.714699Z",
     "start_time": "2025-04-28T13:44:02.939124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from sympy.codegen.fnodes import dimension\n",
    "\n",
    "# Force inject paths (adapt to your system if different)\n",
    "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"PATH\"] += \":/usr/local/cuda/bin\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"EMBEDDINGS_MODEL\"] = \"cohere.embed-english-v3\"\n",
    "os.environ[\"EMBEDDINGS_DIMENSIONS\"] = \"1024\"\n",
    "\n",
    "# Re-check CUDA\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version (Torch):\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"GPU still not detected inside notebook\")"
   ],
   "id": "2b7107a66a3d6607",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "CUDA Version (Torch): 12.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup AWS Profile",
   "id": "cf73d0b003bf1179"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:10.215370Z",
     "start_time": "2025-04-28T13:44:08.978416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure AWS Profile and Region\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "\n",
    "# Assign profile and region to GraphRAGConfig\n",
    "GraphRAGConfig.aws_profile = \"padmin\" #Optional, use if using AWS SSO\n",
    "GraphRAGConfig.aws_region = \"us-east-1\""
   ],
   "id": "d0895acf6fbc98f1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup model",
   "id": "d817c4c9c68f116b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:11.505273Z",
     "start_time": "2025-04-28T13:44:11.503750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Claude model via Bedrock\n",
    "model_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\""
   ],
   "id": "4246fd3faec4a7e5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup BedrockConverse",
   "id": "1f3e98634dc4c67d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:13.807532Z",
     "start_time": "2025-04-28T13:44:13.729896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure BedrockConverse\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "\n",
    "try:\n",
    "    GraphRAGConfig.extraction_llm = BedrockConverse.from_json(f'''\n",
    "    {{\n",
    "        \"model\": \"{model_id}\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"profile_name\": \"{GraphRAGConfig.aws_profile}\",\n",
    "        \"region_name\": \"{GraphRAGConfig.aws_region}\"\n",
    "    }}\n",
    "    ''')\n",
    "    print(f\"Successfully configured Bedrock model: {model_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize BedrockConverse: {str(e)}\")\n",
    "    raise\n",
    "### Display LLM Configuration"
   ],
   "id": "3e1dcab3be3bf81a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully configured Bedrock model: us.anthropic.claude-3-5-sonnet-20240620-v1:0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Display LLM Configuration",
   "id": "23ad3e6f57be3dee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:17.404216Z",
     "start_time": "2025-04-28T13:44:17.402355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display LLM configuration\n",
    "llm = GraphRAGConfig.extraction_llm\n",
    "print(\"LLM class:\", llm.__class__.__name__)\n",
    "print(\"Model ID:\", llm.model)\n",
    "print(\"Temperature:\", llm.temperature)\n",
    "print(\"Max tokens:\", llm.max_tokens)\n",
    "print(\"Profile:\", getattr(llm, 'profile_name', None))\n",
    "print(\"Region:\", getattr(llm, 'region_name', None))"
   ],
   "id": "cd6de0bcdbaf30c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM class: BedrockConverse\n",
      "Model ID: us.anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Temperature: 0.0\n",
      "Max tokens: 4096\n",
      "Profile: padmin\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:26.756261Z",
     "start_time": "2025-04-28T13:44:26.724942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"embed_model model name = {GraphRAGConfig.embed_model.model_name}\")\n",
    "print(f\"embed_model dimension  = {GraphRAGConfig.embed_dimensions}\")"
   ],
   "id": "d71998f8626eb2e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_model model name = cohere.embed-english-v3\n",
      "embed_model dimension  = 1024\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup connection with PostgreSQL",
   "id": "b03ac415378e2820"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:37.682391Z",
     "start_time": "2025-04-28T13:44:37.673933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connect to PostgreSQL Vector Store\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "\n",
    "# PostgreSQL connection string\n",
    "postgre_connection_info = 'postgresql://graphrag:graphragpass@localhost:5432/graphrag_db'\n",
    "\n",
    "# Instantiate vector store using factory\n",
    "vector_store = VectorStoreFactory.for_vector_store(postgre_connection_info)\n",
    "\n",
    "# Optional: confirm\n",
    "print(f\"Vector store initialized: {vector_store}\")"
   ],
   "id": "862a9fe3c0c61e6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized: indexes={'chunk': PGIndex(index_name='chunk', tenant_id=TenantId(value=None), writeable=True, database='graphrag_db', schema_name='graphrag', host='localhost', port=5432, username='graphrag', password='graphragpass', dimensions=1024, embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x71523c1be360>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), enable_iam_db_auth=False, initialized=False), 'statement': PGIndex(index_name='statement', tenant_id=TenantId(value=None), writeable=True, database='graphrag_db', schema_name='graphrag', host='localhost', port=5432, username='graphrag', password='graphragpass', dimensions=1024, embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x71523c1be360>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), enable_iam_db_auth=False, initialized=False)}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup connection with FalkorDB",
   "id": "5fdb3f1e78c21337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:44:42.452185Z",
     "start_time": "2025-04-28T13:44:40.643955Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install https://github.com/awslabs/graphrag-toolkit/archive/refs/tags/v3.4.0.zip#subdirectory=lexical-graph-contrib/falkordb",
   "id": "4c3c51fc31e11696",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/awslabs/graphrag-toolkit/archive/refs/tags/v3.4.0.zip#subdirectory=lexical-graph-contrib/falkordb\r\n",
      "  Using cached https://github.com/awslabs/graphrag-toolkit/archive/refs/tags/v3.4.0.zip\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: FalkorDB in /home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages (from graphrag-toolkit-lexical-graph-falkordb==1.0.0) (1.1.1)\r\n",
      "Requirement already satisfied: redis in /home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages (from graphrag-toolkit-lexical-graph-falkordb==1.0.0) (5.2.1)\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:47:40.575646Z",
     "start_time": "2025-04-28T13:47:40.559576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connect to FalkorDB Graph Store\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.falkordb import FalkorDBGraphStoreFactory\n",
    "\n",
    "# Connection string for FalkorDB\n",
    "falkordb_connection_info = 'falkordb://localhost:6379'\n",
    "\n",
    "# Register the FalkorDB backend with the factory\n",
    "GraphStoreFactory.register(FalkorDBGraphStoreFactory)\n",
    "\n",
    "# Instantiate a graph store using the factory\n",
    "graph_store = GraphStoreFactory.for_graph_store(falkordb_connection_info)\n",
    "\n",
    "# Optional: confirm initialization\n",
    "print(f\"FalkorDB GraphStore initialized: {graph_store}\")"
   ],
   "id": "a91526d4dd20c426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalkorDB GraphStore initialized: log_formatting=RedactedGraphQueryLogFormatting() tenant_id=TenantId(value=None) endpoint_url='localhost:6379' database='graphrag' username=None password=None ssl=False\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "2ec2a722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:47:46.621503Z",
     "start_time": "2025-04-28T13:47:42.807085Z"
    }
   },
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import set_logging_config\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "\n",
    "# Now create query engine\n",
    "query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n",
    "    graph_store,\n",
    "    vector_store\n",
    ")\n",
    "\n",
    "# Now you can query\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "print(response.response)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "_AR_EXP_UpdateEntityIdx: Unable to locate a value with alias l within the record",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mResponseError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     18\u001B[39m query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n\u001B[32m     19\u001B[39m     graph_store,\n\u001B[32m     20\u001B[39m     vector_store\n\u001B[32m     21\u001B[39m )\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Now you can query\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m response = query_engine.query(\u001B[33m\"\u001B[39m\u001B[33mWhat are the differences between Neptune Database and Neptune Analytics?\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     25\u001B[39m \u001B[38;5;28mprint\u001B[39m(response.response)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:52\u001B[39m, in \u001B[36mBaseQueryEngine.query\u001B[39m\u001B[34m(self, str_or_query_bundle)\u001B[39m\n\u001B[32m     50\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(str_or_query_bundle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m     51\u001B[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     query_result = \u001B[38;5;28mself\u001B[39m._query(str_or_query_bundle)\n\u001B[32m     53\u001B[39m dispatcher.event(\n\u001B[32m     54\u001B[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001B[32m     55\u001B[39m )\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m query_result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/lexical_graph_query_engine.py:249\u001B[39m, in \u001B[36mLexicalGraphQueryEngine._query\u001B[39m\u001B[34m(self, query_bundle)\u001B[39m\n\u001B[32m    245\u001B[39m start = time.time()\n\u001B[32m    247\u001B[39m query_bundle = to_embedded_query(query_bundle, GraphRAGConfig.embed_model)\n\u001B[32m--> \u001B[39m\u001B[32m249\u001B[39m results = \u001B[38;5;28mself\u001B[39m.retriever.retrieve(query_bundle)\n\u001B[32m    251\u001B[39m end_retrieve = time.time()\n\u001B[32m    253\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m post_processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.post_processors:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:245\u001B[39m, in \u001B[36mBaseRetriever.retrieve\u001B[39m\u001B[34m(self, str_or_query_bundle)\u001B[39m\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callback_manager.as_trace(\u001B[33m\"\u001B[39m\u001B[33mquery\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callback_manager.event(\n\u001B[32m    242\u001B[39m         CBEventType.RETRIEVE,\n\u001B[32m    243\u001B[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001B[32m    244\u001B[39m     ) \u001B[38;5;28;01mas\u001B[39;00m retrieve_event:\n\u001B[32m--> \u001B[39m\u001B[32m245\u001B[39m         nodes = \u001B[38;5;28mself\u001B[39m._retrieve(query_bundle)\n\u001B[32m    246\u001B[39m         nodes = \u001B[38;5;28mself\u001B[39m._handle_recursive_retrieval(query_bundle, nodes)\n\u001B[32m    247\u001B[39m         retrieve_event.on_end(\n\u001B[32m    248\u001B[39m             payload={EventPayload.NODES: nodes},\n\u001B[32m    249\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/traversal_based_base_retriever.py:92\u001B[39m, in \u001B[36mTraversalBasedBaseRetriever._retrieve\u001B[39m\u001B[34m(self, query_bundle)\u001B[39m\n\u001B[32m     89\u001B[39m start_retrieve = time.time()\n\u001B[32m     91\u001B[39m start_node_ids = \u001B[38;5;28mself\u001B[39m.get_start_node_ids(query_bundle)\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m search_results:SearchResultCollection = \u001B[38;5;28mself\u001B[39m.do_graph_search(query_bundle, start_node_ids)\n\u001B[32m     94\u001B[39m end_retrieve = time.time()\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.processors:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/composite_traversal_based_retriever.py:143\u001B[39m, in \u001B[36mCompositeTraversalBasedRetriever.do_graph_search\u001B[39m\u001B[34m(self, query_bundle, start_node_ids)\u001B[39m\n\u001B[32m    133\u001B[39m subqueries = (\u001B[38;5;28mself\u001B[39m.query_decomposition.decompose_query(query_bundle) \n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.derive_subqueries \n\u001B[32m    135\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m [query_bundle]\n\u001B[32m    136\u001B[39m )\n\u001B[32m    138\u001B[39m tasks = [\n\u001B[32m    139\u001B[39m     \u001B[38;5;28mself\u001B[39m._get_search_results_for_query(subquery) \n\u001B[32m    140\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m subquery \u001B[38;5;129;01min\u001B[39;00m subqueries\n\u001B[32m    141\u001B[39m ]\n\u001B[32m--> \u001B[39m\u001B[32m143\u001B[39m task_results:List[SearchResultCollection] = run_async_tasks(tasks)\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task_result \u001B[38;5;129;01min\u001B[39;00m task_results:\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m search_result \u001B[38;5;129;01min\u001B[39;00m task_result.results:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/async_utils.py:77\u001B[39m, in \u001B[36mrun_async_tasks\u001B[39m\u001B[34m(tasks, show_progress, progress_bar_desc)\u001B[39m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_gather\u001B[39m() -> List[Any]:\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*tasks_to_execute)\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m outputs: List[Any] = asyncio_run(_gather())\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/async_utils.py:33\u001B[39m, in \u001B[36masyncio_run\u001B[39m\u001B[34m(coro)\u001B[39m\n\u001B[32m     30\u001B[39m     loop = asyncio.get_event_loop()\n\u001B[32m     32\u001B[39m     \u001B[38;5;66;03m# If we're here, there's an existing loop but it's not running\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m loop.run_until_complete(coro)\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     36\u001B[39m     \u001B[38;5;66;03m# If we can't get the event loop, we're likely in a different thread, or its already running\u001B[39;00m\n\u001B[32m     37\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/nest_asyncio.py:98\u001B[39m, in \u001B[36m_patch_loop.<locals>.run_until_complete\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m     95\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f.done():\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m     97\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mEvent loop stopped before Future completed.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m f.result()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/asyncio/futures.py:202\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    200\u001B[39m \u001B[38;5;28mself\u001B[39m.__log_traceback = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    201\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m202\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception.with_traceback(\u001B[38;5;28mself\u001B[39m._exception_tb)\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/asyncio/tasks.py:316\u001B[39m, in \u001B[36mTask.__step_run_and_handle_result\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    314\u001B[39m         result = coro.send(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    315\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m         result = coro.throw(exc)\n\u001B[32m    317\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    318\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._must_cancel:\n\u001B[32m    319\u001B[39m         \u001B[38;5;66;03m# Task is cancelled right before coro stops.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/async_utils.py:75\u001B[39m, in \u001B[36mrun_async_tasks.<locals>._gather\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_gather\u001B[39m() -> List[Any]:\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*tasks_to_execute)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/asyncio/tasks.py:385\u001B[39m, in \u001B[36mTask.__wakeup\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m    383\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__wakeup\u001B[39m(\u001B[38;5;28mself\u001B[39m, future):\n\u001B[32m    384\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m         future.result()\n\u001B[32m    386\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    387\u001B[39m         \u001B[38;5;66;03m# This may also be a cancellation.\u001B[39;00m\n\u001B[32m    388\u001B[39m         \u001B[38;5;28mself\u001B[39m.__step(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/asyncio/tasks.py:314\u001B[39m, in \u001B[36mTask.__step_run_and_handle_result\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    310\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    311\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    312\u001B[39m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[32m    313\u001B[39m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m314\u001B[39m         result = coro.send(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    315\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    316\u001B[39m         result = coro.throw(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/composite_traversal_based_retriever.py:123\u001B[39m, in \u001B[36mCompositeTraversalBasedRetriever._get_search_results_for_query\u001B[39m\u001B[34m(self, query_bundle)\u001B[39m\n\u001B[32m    120\u001B[39m     executor.shutdown()\n\u001B[32m    122\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m futures:\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m scored_node \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m future.result():\n\u001B[32m    124\u001B[39m             search_results.append(SearchResult.model_validate_json(scored_node.node.text))\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m SearchResultCollection(results=search_results, entities=entities)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:368\u001B[39m, in \u001B[36mDispatcher.span.<locals>.async_wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    360\u001B[39m \u001B[38;5;28mself\u001B[39m.span_enter(\n\u001B[32m    361\u001B[39m     id_=id_,\n\u001B[32m    362\u001B[39m     bound_args=bound_args,\n\u001B[32m   (...)\u001B[39m\u001B[32m    365\u001B[39m     tags=tags,\n\u001B[32m    366\u001B[39m )\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m368\u001B[39m     result = \u001B[38;5;28;01mawait\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    370\u001B[39m     \u001B[38;5;28mself\u001B[39m.event(SpanDropEvent(span_id=id_, err_str=\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:276\u001B[39m, in \u001B[36mBaseRetriever.aretrieve\u001B[39m\u001B[34m(self, str_or_query_bundle)\u001B[39m\n\u001B[32m    271\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callback_manager.as_trace(\u001B[33m\"\u001B[39m\u001B[33mquery\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    272\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callback_manager.event(\n\u001B[32m    273\u001B[39m         CBEventType.RETRIEVE,\n\u001B[32m    274\u001B[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001B[32m    275\u001B[39m     ) \u001B[38;5;28;01mas\u001B[39;00m retrieve_event:\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m         nodes = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._aretrieve(query_bundle=query_bundle)\n\u001B[32m    277\u001B[39m         nodes = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._ahandle_recursive_retrieval(\n\u001B[32m    278\u001B[39m             query_bundle=query_bundle, nodes=nodes\n\u001B[32m    279\u001B[39m         )\n\u001B[32m    280\u001B[39m         retrieve_event.on_end(\n\u001B[32m    281\u001B[39m             payload={EventPayload.NODES: nodes},\n\u001B[32m    282\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:307\u001B[39m, in \u001B[36mBaseRetriever._aretrieve\u001B[39m\u001B[34m(self, query_bundle)\u001B[39m\n\u001B[32m    301\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_aretrieve\u001B[39m(\u001B[38;5;28mself\u001B[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001B[32m    302\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Asynchronously retrieve nodes given query.\u001B[39;00m\n\u001B[32m    303\u001B[39m \n\u001B[32m    304\u001B[39m \u001B[33;03m    Implemented by the user.\u001B[39;00m\n\u001B[32m    305\u001B[39m \n\u001B[32m    306\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m307\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve(query_bundle)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/traversal_based_base_retriever.py:92\u001B[39m, in \u001B[36mTraversalBasedBaseRetriever._retrieve\u001B[39m\u001B[34m(self, query_bundle)\u001B[39m\n\u001B[32m     89\u001B[39m start_retrieve = time.time()\n\u001B[32m     91\u001B[39m start_node_ids = \u001B[38;5;28mself\u001B[39m.get_start_node_ids(query_bundle)\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m search_results:SearchResultCollection = \u001B[38;5;28mself\u001B[39m.do_graph_search(query_bundle, start_node_ids)\n\u001B[32m     94\u001B[39m end_retrieve = time.time()\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.processors:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001B[39m, in \u001B[36mDispatcher.span.<locals>.wrapper\u001B[39m\u001B[34m(func, instance, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m             _logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     result = func(*args, **kwargs)\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio.Future):\n\u001B[32m    324\u001B[39m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[32m    325\u001B[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/chunk_based_search.py:78\u001B[39m, in \u001B[36mChunkBasedSearch.do_graph_search\u001B[39m\u001B[34m(self, query_bundle, start_node_ids)\u001B[39m\n\u001B[32m     75\u001B[39m     executor.shutdown()\n\u001B[32m     77\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m futures:\n\u001B[32m---> \u001B[39m\u001B[32m78\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m future.result():\n\u001B[32m     79\u001B[39m             search_results.append(result)\n\u001B[32m     81\u001B[39m search_results_collection = \u001B[38;5;28mself\u001B[39m._to_search_results_collection(search_results) \n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__get_result()\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/concurrent/futures/thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28mself\u001B[39m.fn(*\u001B[38;5;28mself\u001B[39m.args, **\u001B[38;5;28mself\u001B[39m.kwargs)\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/retrieval/retrievers/chunk_based_search.py:49\u001B[39m, in \u001B[36mChunkBasedSearch.chunk_based_graph_search\u001B[39m\u001B[34m(self, chunk_id)\u001B[39m\n\u001B[32m     37\u001B[39m cypher = \u001B[38;5;28mself\u001B[39m.create_cypher_query(\u001B[33mf\u001B[39m\u001B[33m'''\u001B[39m\n\u001B[32m     38\u001B[39m \u001B[33m// chunk-based graph search                                  \u001B[39m\n\u001B[32m     39\u001B[39m \u001B[33mMATCH (l:`__Statement__`)-[:`__PREVIOUS__`*0..1]-(:`__Statement__`)-[:`__BELONGS_TO__`]->(t:`__Topic__`)-[:`__MENTIONED_IN__`]->(c:`__Chunk__`)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[33mWHERE \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.graph_store.node_id(\u001B[33m\"\u001B[39m\u001B[33mc.chunkId\u001B[39m\u001B[33m\"\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m = $chunkId\u001B[39m\n\u001B[32m     41\u001B[39m \u001B[33m\u001B[39m\u001B[33m'''\u001B[39m)\n\u001B[32m     43\u001B[39m properties = {\n\u001B[32m     44\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mchunkId\u001B[39m\u001B[33m'\u001B[39m: chunk_id,\n\u001B[32m     45\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mlimit\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28mself\u001B[39m.args.query_limit,\n\u001B[32m     46\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mstatementLimit\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28mself\u001B[39m.args.intermediate_limit\n\u001B[32m     47\u001B[39m }\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.graph_store.execute_query(cypher, properties)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/graphrag_toolkit/lexical_graph/storage/graph/falkordb/falkordb_graph_store.py:169\u001B[39m, in \u001B[36mFalkorDBDatabaseClient.execute_query\u001B[39m\u001B[34m(self, cypher, parameters, correlation_id)\u001B[39m\n\u001B[32m    166\u001B[39m start = time.time()\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m     response = \u001B[38;5;28mself\u001B[39m.client.query(\n\u001B[32m    170\u001B[39m         q=request_log_entry_parameters.format_query_with_query_ref(cypher),\n\u001B[32m    171\u001B[39m         params=parameters\n\u001B[32m    172\u001B[39m     )\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ResponseError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    174\u001B[39m     logger.error(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mQuery execution failed: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Query: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcypher\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparameters\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/falkordb/graph.py:115\u001B[39m, in \u001B[36mGraph.query\u001B[39m\u001B[34m(self, q, params, timeout)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mquery\u001B[39m(\u001B[38;5;28mself\u001B[39m, q: \u001B[38;5;28mstr\u001B[39m, params: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mobject\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    100\u001B[39m           timeout: Optional[\u001B[38;5;28mint\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m) -> QueryResult:\n\u001B[32m    101\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[33;03m    Executes a query against the graph.\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[33;03m    See: https://docs.falkordb.com/commands/graph.query.html\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    112\u001B[39m \n\u001B[32m    113\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._query(q, params=params, timeout=timeout, read_only=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/falkordb/graph.py:91\u001B[39m, in \u001B[36mGraph._query\u001B[39m\u001B[34m(self, q, params, timeout, read_only)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;66;03m# issue query\u001B[39;00m\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m     response = \u001B[38;5;28mself\u001B[39m.execute_command(*command)\n\u001B[32m     92\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m QueryResult(\u001B[38;5;28mself\u001B[39m, response)\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m SchemaVersionMismatchException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     94\u001B[39m     \u001B[38;5;66;03m# client view over the graph schema is out of sync\u001B[39;00m\n\u001B[32m     95\u001B[39m     \u001B[38;5;66;03m# set client version and refresh local schema\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/client.py:559\u001B[39m, in \u001B[36mRedis.execute_command\u001B[39m\u001B[34m(self, *args, **options)\u001B[39m\n\u001B[32m    558\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexecute_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **options):\n\u001B[32m--> \u001B[39m\u001B[32m559\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._execute_command(*args, **options)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/client.py:567\u001B[39m, in \u001B[36mRedis._execute_command\u001B[39m\u001B[34m(self, *args, **options)\u001B[39m\n\u001B[32m    565\u001B[39m conn = \u001B[38;5;28mself\u001B[39m.connection \u001B[38;5;129;01mor\u001B[39;00m pool.get_connection(command_name, **options)\n\u001B[32m    566\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m conn.retry.call_with_retry(\n\u001B[32m    568\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m._send_command_parse_response(\n\u001B[32m    569\u001B[39m             conn, command_name, *args, **options\n\u001B[32m    570\u001B[39m         ),\n\u001B[32m    571\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m error: \u001B[38;5;28mself\u001B[39m._disconnect_raise(conn, error),\n\u001B[32m    572\u001B[39m     )\n\u001B[32m    573\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    574\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.connection:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/retry.py:62\u001B[39m, in \u001B[36mRetry.call_with_retry\u001B[39m\u001B[34m(self, do, fail)\u001B[39m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m do()\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;28mself\u001B[39m._supported_errors \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[32m     64\u001B[39m         failures += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/client.py:568\u001B[39m, in \u001B[36mRedis._execute_command.<locals>.<lambda>\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    565\u001B[39m conn = \u001B[38;5;28mself\u001B[39m.connection \u001B[38;5;129;01mor\u001B[39;00m pool.get_connection(command_name, **options)\n\u001B[32m    566\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    567\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m conn.retry.call_with_retry(\n\u001B[32m--> \u001B[39m\u001B[32m568\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m._send_command_parse_response(\n\u001B[32m    569\u001B[39m             conn, command_name, *args, **options\n\u001B[32m    570\u001B[39m         ),\n\u001B[32m    571\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m error: \u001B[38;5;28mself\u001B[39m._disconnect_raise(conn, error),\n\u001B[32m    572\u001B[39m     )\n\u001B[32m    573\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    574\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.connection:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/client.py:542\u001B[39m, in \u001B[36mRedis._send_command_parse_response\u001B[39m\u001B[34m(self, conn, command_name, *args, **options)\u001B[39m\n\u001B[32m    538\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    539\u001B[39m \u001B[33;03mSend a command and parse the response\u001B[39;00m\n\u001B[32m    540\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    541\u001B[39m conn.send_command(*args, **options)\n\u001B[32m--> \u001B[39m\u001B[32m542\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.parse_response(conn, command_name, **options)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/client.py:584\u001B[39m, in \u001B[36mRedis.parse_response\u001B[39m\u001B[34m(self, connection, command_name, **options)\u001B[39m\n\u001B[32m    582\u001B[39m         options.pop(NEVER_DECODE)\n\u001B[32m    583\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m584\u001B[39m         response = connection.read_response()\n\u001B[32m    585\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ResponseError:\n\u001B[32m    586\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m EMPTY_RESPONSE \u001B[38;5;129;01min\u001B[39;00m options:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/redis/connection.py:616\u001B[39m, in \u001B[36mAbstractConnection.read_response\u001B[39m\u001B[34m(self, disable_decoding, disconnect_on_error, push_request)\u001B[39m\n\u001B[32m    614\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, ResponseError):\n\u001B[32m    615\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m616\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m response\n\u001B[32m    617\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    618\u001B[39m         \u001B[38;5;28;01mdel\u001B[39;00m response  \u001B[38;5;66;03m# avoid creating ref cycles\u001B[39;00m\n",
      "\u001B[31mResponseError\u001B[39m: _AR_EXP_UpdateEntityIdx: Unable to locate a value with alias l within the record"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "3b5a947e",
   "metadata": {},
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb78418c",
   "metadata": {},
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41035822",
   "metadata": {},
   "source": [
    "#### Set subretriever\n",
    "\n",
    "In the example below, the `TraversalBasedRetriever` is configured with a `ChunkBasedSearch` subretriever."
   ]
  },
  {
   "cell_type": "code",
   "id": "90d04b97",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import ChunkBasedSearch\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    retrievers=[ChunkBasedSearch]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d174f696",
   "metadata": {},
   "source": [
    "### SemanticGuidedRetriever\n",
    "\n",
    "See [SemanticGuidedRetriever](https://github.com/awslabs/graphrag-toolkit/blob/main/docs/lexical-graph/querying.md#semanticguidedretriever)."
   ]
  },
  {
   "cell_type": "code",
   "id": "9d1f3184",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3416845",
   "metadata": {},
   "source": [
    "#### Set subretrievers"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec1adddb",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import StatementCosineSimilaritySearch, KeywordRankingSearch, SemanticBeamGraphSearch\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    retrievers=[\n",
    "        StatementCosineSimilaritySearch, \n",
    "        KeywordRankingSearch, \n",
    "        SemanticBeamGraphSearch\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b234dc61",
   "metadata": {},
   "source": [
    "#### Reranking beam search (CPU)\n",
    "\n",
    "The example below uses a `SentenceReranker` with a `RerankingBeamGraphSearch` to rerank statements while conducting the beam search."
   ]
  },
  {
   "cell_type": "code",
   "id": "902acaef",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import RerankingBeamGraphSearch, StatementCosineSimilaritySearch, KeywordRankingSearch\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = SentenceReranker(\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    retrievers=[\n",
    "        cosine_retriever,\n",
    "        keyword_retriever,\n",
    "        beam_retriever\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "717049be",
   "metadata": {},
   "source": [
    "#### Reranking beam search (GPU)\n",
    "\n",
    "The example below uses a `BGEReranker` with a `RerankingBeamGraphSearch` to rerank statements while conducting the beam search.\n",
    "\n",
    "There will be a delay the first time this runs while the reranker downloads tensors."
   ]
  },
  {
   "cell_type": "code",
   "id": "06c3b363",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import RerankingBeamGraphSearch, StatementCosineSimilaritySearch, KeywordRankingSearch\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors.bge_reranker import BGEReranker\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = BGEReranker(\n",
    "    gpu_id=0,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    retrievers=[\n",
    "        cosine_retriever,\n",
    "        keyword_retriever,\n",
    "        beam_retriever\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ba2ac35",
   "metadata": {},
   "source": [
    "#### Post-processors \n",
    "\n",
    "The example below uses a `StatementDiversityPostProcessor`, `SentenceReranker` and `StatementEnhancementPostProcessor`.\n",
    "\n",
    "  - `SentenceReranker` - Reranks statements using the `mixedbread-ai/mxbai-rerank-xsmall-v1` model. \n",
    "\n",
    "  - `StatementEnhancementPostProcessor` - Enhances statements by using chunk context and an LLM to improve content while preserving original metadata.\n",
    "\n",
    "  - `StatementDiversityPostProcessor` - Removes similar statements using TF-IDF similarity with a default threshold of 0.975 to ensure diversity in the processed nodes.\n",
    "\n",
    "Before running `StatementDiversityPostProcessor` for the first time, load the following package:\n",
    "\n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "If you're running on a GPU device, you can replace the `SentenceReranker` with a `BGEReranker`, which reranks statements using the ``BAAI/bge-reranker-v2-minicpm-layerwise`` model."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f2d46a3",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_sm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef08819d",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker, StatementDiversityPostProcessor, StatementEnhancementPostProcessor\n",
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store, \n",
    "    vector_store,\n",
    "    post_processors=[\n",
    "        SentenceReranker(), \n",
    "        StatementDiversityPostProcessor(), \n",
    "        StatementEnhancementPostProcessor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
