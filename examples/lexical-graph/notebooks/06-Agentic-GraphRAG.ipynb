{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22700f2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you haven't already, install the toolkit and dependencies using the [Setup](./00-Setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5a0dd",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) is an open protocol that standardizes how applications provide context to LLMs.\n",
    "\n",
    "In this example, we're going to create a 'catalog' of tools, one per tenant in a [multi-tenant](https://github.com/awslabs/graphrag-toolkit/blob/main/docs/lexical-graph/multi-tenancy.md) graph. Each tool is capable of answering domain-specific questions based on the data in its tenant graph. This catalog will be advertised to clients via an MCP server. Clients (typically agents and LLMs) can then browse the catalog and choose appropriate tools for addressing their information goals.\n",
    "\n",
    "Each tool in the catalog is accompanied by an auto-generated description that helps a client understand the domain, scope, potential uses and kinds of questions covered by the tool. The catalog also includes a 'search' tool, which, given the name of an entity or concept, recommends one or more domain tools with knowledge of the search term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8788590",
   "metadata": {},
   "source": [
    "### Additional setup\n",
    "\n",
    "#### Create tenant-specific lexical graphs\n",
    "\n",
    "Besides the initial setup described above, this example requires you to have created two tenant-specific lexical graphs: a Neptune documentation lexical graph (installed in the _default_ tenant graph), and an Amazon OpenSearch documentation lexical graph (installed in the `aoss` tenant graph):\n",
    "\n",
    "  - To create the Neptune documentation lexical graph, run either notebook [01-Combined-Extract-and-Build](./01-Combined-Extract-and-Build.ipynb) or notebook [02-Separate-Extract-and-Build](./02-Separate-Extract-and-Build.ipynb).\n",
    "  - To create the Amazon OpenSearch documentation lexical graph, run the create cell in notebook [05-Multi-Tenancy](./05-Multi-Tenancy.ipynb)\n",
    "\n",
    "#### Provide Bedrock model access for Claude 3.7 Sonnet\n",
    "\n",
    "Ensufre you have provided model acess in Amazon Bedrock for `anthropic.claude-3-7-sonnet-20250219-v1:0`\n",
    "\n",
    "#### Install additional dependencies\n",
    "\n",
    "The last thing you need to do is install these additional dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2701e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastmcp\n",
      "  Downloading fastmcp-2.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting strands-agents\n",
      "  Downloading strands_agents-0.1.5-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from fastmcp) (1.2.2)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from fastmcp) (0.28.1)\n",
      "Collecting mcp<2.0.0,>=1.9.0 (from fastmcp)\n",
      "  Downloading mcp-1.9.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting openapi-pydantic>=0.5.1 (from fastmcp)\n",
      "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting python-dotenv>=1.1.0 (from fastmcp)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: rich>=13.9.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from fastmcp) (13.9.4)\n",
      "Collecting typer>=0.15.2 (from fastmcp)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting websockets>=14.0 (from fastmcp)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from strands-agents) (1.38.1)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from strands-agents) (1.38.1)\n",
      "Collecting docstring-parser<0.16.0,>=0.15 (from strands-agents)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from strands-agents) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from strands-agents) (4.13.2)\n",
      "Collecting watchdog<7.0.0,>=6.0.0 (from strands-agents)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.4.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx>=0.28.1->fastmcp) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx>=0.28.1->fastmcp) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx>=0.28.1->fastmcp) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpx>=0.28.1->fastmcp) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp) (0.14.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.9.0->fastmcp)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.9.0->fastmcp)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.9.0->fastmcp)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.9.0->fastmcp)\n",
      "  Downloading sse_starlette-2.3.5-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from mcp<2.0.0,>=1.9.0->fastmcp) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from mcp<2.0.0,>=1.9.0->fastmcp) (0.34.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (6.11.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents)\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.7 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents) (2.32.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from opentelemetry-proto==1.33.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents) (5.29.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk<2.0.0,>=1.30.0->strands-agents)\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents) (0.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from rich>=13.9.4->fastmcp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from rich>=13.9.4->fastmcp) (2.19.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from typer>=0.15.2->fastmcp) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.2->fastmcp)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from anyio->httpx>=0.28.1->fastmcp) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (1.17.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents) (3.4.1)\n",
      "Downloading fastmcp-2.5.1-py3-none-any.whl (105 kB)\n",
      "Downloading strands_agents-0.1.5-py3-none-any.whl (103 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.9.1-py3-none-any.whl (130 kB)\n",
      "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
      "Downloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sse_starlette-2.3.5-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: websockets, watchdog, shellingham, python-multipart, python-dotenv, opentelemetry-proto, httpx-sse, googleapis-common-protos, docstring-parser, deprecated, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, typer, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, openapi-pydantic, opentelemetry-sdk, mcp, opentelemetry-exporter-otlp-proto-http, fastmcp, strands-agents\n",
      "Successfully installed deprecated-1.2.18 docstring-parser-0.15 fastmcp-2.5.1 googleapis-common-protos-1.70.0 httpx-sse-0.4.0 mcp-1.9.1 openapi-pydantic-0.5.1 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 shellingham-1.5.4 sse-starlette-2.3.5 strands-agents-0.1.5 typer-0.16.0 watchdog-6.0.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastmcp strands-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf844b9",
   "metadata": {},
   "source": [
    "## Create an MCP server\n",
    "\n",
    "The following cell creates an MCP server that hosts a catalog of tools – one per tenant graph. The cell takes a few seconds to run while the tool descriptions are auto-generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6762d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server initialized\n"
     ]
    }
   ],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory, VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.protocols import create_mcp_server\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "mcp_server = create_mcp_server(graph_store, vector_store)\n",
    "\n",
    "print('Server initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29f4ee",
   "metadata": {},
   "source": [
    "### Start the server\n",
    "\n",
    "The cell below starts the MCP server using the Streamable HTTP transport on a background thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99abadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/28/25 14:26:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting MCP server <span style=\"color: #008000; text-decoration-color: #008000\">'LexicalGraphServer'</span> with transport                  <a href=\"file:///home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/fastmcp/server/server.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">server.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/fastmcp/server/server.py#823\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">823</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'streamable-http'</span> on <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://127.0.0.1:8000/mcp</span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/28/25 14:26:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting MCP server \u001b[32m'LexicalGraphServer'\u001b[0m with transport                  \u001b]8;id=995065;file:///home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/fastmcp/server/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=333750;file:///home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/fastmcp/server/server.py#823\u001b\\\u001b[2m823\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'streamable-http'\u001b[0m on \u001b[4;94mhttp://127.0.0.1:8000/mcp\u001b[0m                           \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:FastMCP.fastmcp.server.server:Starting MCP server 'LexicalGraphServer' with transport 'streamable-http' on http://127.0.0.1:8000/mcp\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def run_server():\n",
    "    mcp_server.run(transport='streamable-http', log_level='warning')\n",
    "    \n",
    "thread = threading.Thread(target=run_server)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad5e09",
   "metadata": {},
   "source": [
    "## Create an MCP client and AI agent\n",
    "\n",
    "[Strands Agents](https://strandsagents.com/latest/) is an open source SDK that takes a model-driven approach to building and running AI agents in just a few lines of code.\n",
    "\n",
    "In the cell below we create an MCP client that we can then use in a Strands Agent for answering cross-domain questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c8dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from strands.tools.mcp.mcp_client import MCPClient\n",
    "\n",
    "def create_streamable_http_transport():\n",
    "    return streamablehttp_client('http://localhost:8000/mcp/')\n",
    "\n",
    "mcp_client = MCPClient(create_streamable_http_transport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6bc50",
   "metadata": {},
   "source": [
    "### Inspect the tool descriptions\n",
    "\n",
    "The code below prints out the tool descriptions that have been auto-generated from the tenant graphs. Each tool is named after its tenant. The tool for the default tenant graph is named `tenant_`. Note that besides the tenant-specific tools, there is also a `search_` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f962745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_: Domain: Amazon Neptune and Graph Database Technologies\n",
      "\n",
      "Scope: This knowledge base covers Amazon Neptune, a fully managed graph database service, along with related graph database technologies, query languages, and AWS services. It encompasses software components, documentation, and roles involved in the Neptune ecosystem.\n",
      "\n",
      "Uses: This knowledge base can be utilized for understanding Amazon Neptune's capabilities, its integration with other AWS services, supported query languages, and how it compares to other graph database solutions. It's valuable for developers, database administrators, and cloud architects working with graph databases, particularly in AWS environments. The knowledge base can assist in decision-making for database selection, understanding data loading processes, and identifying compatible tools and services for Neptune.\n",
      "\n",
      "Example questions:\n",
      "1. What query languages does Amazon Neptune support?\n",
      "2. How does Neptune integrate with other AWS services?\n",
      "3. What are the main components of a Neptune DB cluster?\n",
      "4. How does Neptune compare to other graph database solutions?\n",
      "5. What tools are available for loading data into Neptune?\n",
      "6. How does Neptune handle backups and data storage?\n",
      "7. What role does Gremlin play in the Neptune ecosystem?\n",
      "8. How does Neptune support RDF and SPARQL?\n",
      "9. What documentation resources are available for Amazon Neptune?\n",
      "10. How does Neptune Analytics complement the core Neptune database?\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "aoss: Domain: Amazon Web Services (AWS) OpenSearch and related services\n",
      "\n",
      "Scope: This knowledge base covers AWS OpenSearch services, including OpenSearch Serverless and OpenSearch Service, along with their components, features, and integrations within the AWS ecosystem. It encompasses software components, authentication methods, storage options, and documentation related to these services.\n",
      "\n",
      "Uses: \n",
      "- Compare different OpenSearch service options\n",
      "- Understand the features and capabilities of OpenSearch Serverless and OpenSearch Service\n",
      "- Identify integrations between OpenSearch services and other AWS products\n",
      "- Explore authentication and security options for OpenSearch\n",
      "- Analyze storage and data management solutions for OpenSearch\n",
      "- Access relevant documentation and tutorials for OpenSearch services\n",
      "- Understand billing and pricing models for OpenSearch services\n",
      "- Explore advanced features like Vector Search and time series analysis\n",
      "\n",
      "Example questions:\n",
      "1. What are the main differences between OpenSearch Serverless and OpenSearch Service?\n",
      "2. How does OpenSearch Serverless integrate with Amazon S3?\n",
      "3. What authentication methods are supported by OpenSearch Serverless?\n",
      "4. How is capacity measured in OpenSearch Serverless?\n",
      "5. What advanced search capabilities are available in OpenSearch services?\n",
      "6. How does AWS simplify the management of OpenSearch through Serverless collections?\n",
      "7. What documentation resources are available for learning about OpenSearch services?\n",
      "8. How does OpenSearch Service handle data storage compared to OpenSearch Serverless?\n",
      "9. What are OpenSearch Compute Units (OCUs) and how are they used?\n",
      "10. How does Amazon bill for OpenSearch Serverless usage?\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "multihop: Domain: Celebrity, Sports, and Business Knowledge Base\n",
      "\n",
      "Scope: This knowledge base covers a wide range of entities including celebrities, athletes, sports teams, companies, and their interrelationships. It encompasses professional sports (particularly American football, baseball, and soccer), entertainment industry figures, tech companies, and business leaders.\n",
      "\n",
      "Uses: This knowledge base can be utilized for analyzing sports team performance, tracking celebrity relationships and careers, understanding business connections and acquisitions in the tech industry, and exploring the intersections between sports, entertainment, and business. It's valuable for sports analytics, celebrity news tracking, business intelligence, and social network analysis.\n",
      "\n",
      "Example questions:\n",
      "1. Which NFL quarterbacks have the highest pass completion rates to specific receivers?\n",
      "2. What are the recent relationship developments between Taylor Swift and Travis Kelce?\n",
      "3. How has the leadership of OpenAI changed over time, including the roles of Sam Altman and Greg Brockman?\n",
      "4. What is the current competitive landscape among major tech companies like Google, Apple, and Microsoft?\n",
      "5. How have the Kansas City Chiefs performed against their recent opponents?\n",
      "6. What are the business relationships between companies like FTX, Alameda Research, and their founders?\n",
      "7. Who are the key players in the development and promotion of AI technologies like ChatGPT?\n",
      "8. How have celebrity relationships, such as those of Will Smith and Jada Pinkett Smith, evolved over time?\n",
      "9. What are the recent transfer activities and performance statistics for soccer players like Lionel Messi?\n",
      "10. How have recent acquisitions in the gaming industry, such as Microsoft's purchase of Activision Blizzard, affected the market?\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "search_: Given a search term, returns the name of one or more tools that can be used to provide information about the search term. Use this tool to help find other tools that can answer a query.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "\n",
    "with mcp_client:\n",
    "    \n",
    "    tools = mcp_client.list_tools_sync()\n",
    "    \n",
    "    for tool in tools:\n",
    "        print(f\"{tool.tool_spec['name']}: {tool.tool_spec['description']}\")\n",
    "        print('\\n-------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911409f5",
   "metadata": {},
   "source": [
    "### Create an agent and ask a question\n",
    "\n",
    "We can now create a Strands AI Agent, and ask a question. The agent will choose the most appropriate tools for answering the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a023070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you with information about Amazon Neptune and recent legal battles involving Amazon. Let me break this down into two parts using the appropriate tools.\n",
      "\n",
      "First, let me get information about Amazon Neptune:\n",
      "Tool #3: default_\n",
      "Now, let me look for information about Amazon's recent legal battles. Since the Neptune knowledge base is focused on the database technology and not Amazon's legal issues, I'll need to search for an appropriate tool first:\n",
      "Tool #4: search_\n",
      "\n",
      "Tool #5: multihop\n",
      "Based on the information I've gathered, I can now provide you with details about Amazon Neptune and recent legal battles involving Amazon:\n",
      "\n",
      "## Amazon Neptune\n",
      "\n",
      "Amazon Neptune is a fully managed graph database service that makes it easy to work with graph data in the AWS Cloud. Here are its key features and capabilities:\n",
      "\n",
      "1. **Graph Database Types**:\n",
      "   - Supports property graphs with Gremlin and openCypher query languages\n",
      "   - Supports RDF (Resource Description Format) graphs with SPARQL query language\n",
      "\n",
      "2. **Key Components**:\n",
      "   - **Neptune Database**: A serverless graph database designed for optimal availability and scalability\n",
      "   - **Neptune Analytics**: A complementary analytics engine for getting insights and finding trends in graph data\n",
      "\n",
      "3. **Core Features**:\n",
      "   - High-performance, purpose-built graph database engine\n",
      "   - Fast and reliable service\n",
      "   - Supports open graph APIs\n",
      "   - Security features including data encryption in transit\n",
      "   - Continuous backup to Amazon S3\n",
      "   - Eliminates the need for manual setup and backups\n",
      "\n",
      "4. **Use Cases**:\n",
      "   - Network security applications\n",
      "   - Low-latency analytic queries\n",
      "   - Connected data applications\n",
      "\n",
      "## Recent Legal Battles Involving Amazon\n",
      "\n",
      "Amazon has been involved in several significant legal battles recently:\n",
      "\n",
      "1. **FTC Antitrust Lawsuit (2023)**:\n",
      "   - Described by some as \"long overdue\"\n",
      "   - Concerns Amazon's business practices and its impact on merchants\n",
      "   - Merchants have expressed grievances over rising fees, competition from Amazon itself, and Amazon's power over sellers\n",
      "   - Amazon's general counsel David Zapolsky argued that stopping Amazon from highlighting low prices would be contrary to antitrust law goals\n",
      "\n",
      "2. **EU Antitrust Investigations and Settlements**:\n",
      "   - Amazon reached a settlement with the European Union over competition probes in late 2022\n",
      "   - The probes examined Amazon's use of merchant data to boost its own retail business\n",
      "   - Amazon committed to stop using non-public data from marketplace sellers\n",
      "   - Amazon pledged to treat all sellers equally regardless of whether they use Amazon's logistics services\n",
      "\n",
      "3. **EU Competition Concerns on iRobot Acquisition**:\n",
      "   - The EU has expressed formal competition concerns regarding Amazon's purchase of iRobot\n",
      "   - These concerns emerge despite previous commitments from Amazon after earlier antitrust investigations\n",
      "   - The case involves concerns about competition between iRobot and rival robot vacuum cleaners on Amazon's marketplace\n",
      "\n",
      "These legal battles reflect ongoing regulatory scrutiny of Amazon's business practices, particularly regarding its dual role as both a marketplace operator and a retailer competing with third-party sellers on its platform."
     ]
    }
   ],
   "source": [
    "with mcp_client:\n",
    "\n",
    "    tools = mcp_client.list_tools_sync()\n",
    "    agent = Agent(tools=tools)\n",
    "    \n",
    "    response = agent(\"Tell me about Amazon Neptune and recent legal battles in which Amazon has been involved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c13c2-6db3-4aef-abf0-0aab82611951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
