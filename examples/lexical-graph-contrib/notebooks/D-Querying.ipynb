{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Querying",
   "id": "3bfeb79c9431a3c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:40:41.673531Z",
     "start_time": "2025-05-06T15:40:39.685307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.falkordb import FalkorDBGraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "\n",
    "# Register the FalkorDB backend with the factory\n",
    "GraphStoreFactory.register(FalkorDBGraphStoreFactory)\n",
    "\n",
    "# Create graph and vector stores\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])"
   ],
   "id": "6edfdf2594abab7c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:13:13.592986Z",
     "start_time": "2025-05-06T13:13:13.541120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hydrate GraphRAGConfig and warm up LLM + embedding clients\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine, set_logging_config\n",
    "from graphrag_toolkit.lexical_graph.tenant_id import TenantId\n",
    "\n",
    "# Optional: enable logging to see detailed progress\n",
    "set_logging_config(\"INFO\")\n",
    "\n",
    "# First, run a bootstrap call with tenant_id to hydrate all dynamic config internals\n",
    "_ = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    tenant_id=TenantId(\"awsgraph1\")  # Ensures embedding + region config loads\n",
    ")\n"
   ],
   "id": "7e99b95a94fb4013",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:13:34.884972Z",
     "start_time": "2025-05-06T13:13:27.494978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import (\n",
    "    RerankingBeamGraphSearch,\n",
    "    StatementCosineSimilaritySearch,\n",
    "    KeywordRankingSearch\n",
    ")\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "\n",
    "# Build advanced retrievers\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = SentenceReranker(batch_size=128)\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "# Now initialize the real query engine (tenant_id optional since hydrated already)\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    retrievers=[cosine_retriever, keyword_retriever, beam_retriever]\n",
    ")\n",
    "\n",
    "# Execute a query\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "print(response.response)\n"
   ],
   "id": "d3d8695141e3f7d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 09:13:28:INFO:datasets       :PyTorch version 2.7.0 available.\n",
      "I apologize, but I do not have enough information from the provided search results to accurately answer your question about the differences between Neptune Database and Neptune Analytics. The search results are empty, so I cannot make any factual statements or comparisons between these two services. To provide a proper response, I would need specific information about both Neptune Database and Neptune Analytics from reliable sources.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:11:54.845042Z",
     "start_time": "2025-05-06T13:11:46.652484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hydrate GraphRAGConfig and warm up LLM + embedding clients\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine, set_logging_config\n",
    "from graphrag_toolkit.lexical_graph.tenant_id import TenantId\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import (\n",
    "    RerankingBeamGraphSearch,\n",
    "    StatementCosineSimilaritySearch,\n",
    "    KeywordRankingSearch\n",
    ")\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker\n",
    "\n",
    "# Optional: enable logging to see detailed progress\n",
    "set_logging_config(\"INFO\")\n",
    "\n",
    "# First, run a bootstrap call with tenant_id to hydrate all dynamic config internals\n",
    "_ = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    tenant_id=TenantId(\"awsgraph1\")  # This ensures embedding and region config loads\n",
    ")\n",
    "\n",
    "# Then build advanced retrievers\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = SentenceReranker(batch_size=128)\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "# Now initialize the real query engine (tenant_id optional since hydrated already)\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store=graph_store,\n",
    "    vector_store=vector_store,\n",
    "    retrievers=[cosine_retriever, keyword_retriever, beam_retriever]\n",
    ")\n",
    "\n",
    "# Execute a query\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "print(response.response)\n"
   ],
   "id": "f361c0e178dbb6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 09:11:47:INFO:datasets       :PyTorch version 2.7.0 available.\n",
      "I apologize, but I do not have enough information from the provided search results to accurately answer your question about the differences between Neptune Database and Neptune Analytics. The search results are empty, so I cannot make any factual statements or comparisons between these two services. To provide a proper answer, I would need specific information about the features, capabilities, and use cases of both Neptune Database and Neptune Analytics.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "152bf09abb65e4c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "802aa1e95e76362b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:13:54.785765Z",
     "start_time": "2025-05-06T13:13:54.783363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure AWS Profile and Region\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "print(f\"GraphRAGConfig: {GraphRAGConfig}\")"
   ],
   "id": "a3004bf09050ea99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAGConfig: _GraphRAGConfig(_aws_profile='padmin', _aws_region='us-east-1', _aws_clients={}, _extraction_llm=None, _response_llm=BedrockConverse(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ed0af3b05c0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7ed19326ade0>, completion_to_prompt=<function default_completion_to_prompt at 0x7ed1930d6660>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='us.anthropic.claude-3-5-sonnet-20240620-v1:0', temperature=0.0, max_tokens=4096, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, guardrail_identifier=None, guardrail_version=None, trace=None, additional_kwargs={}), _embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ed0af3b05c0>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), _embed_dimensions=1024, _reranking_model=None, _extraction_num_workers=None, _extraction_num_threads_per_worker=None, _extraction_batch_size=None, _build_num_workers=None, _build_batch_size=None, _build_batch_write_size=None, _batch_writes_enabled=None, _include_domain_labels=None, _enable_cache=False)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:09:25.866739Z",
     "start_time": "2025-05-06T13:09:18.965759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import set_logging_config\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.tenant_id import TenantId\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import RerankingBeamGraphSearch, StatementCosineSimilaritySearch, KeywordRankingSearch\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker, SentenceReranker, StatementDiversityPostProcessor, StatementEnhancementPostProcessor\n",
    "import os\n",
    "\n",
    "set_logging_config('INFO')\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store,\n",
    "    vector_store,\n",
    "    tenant_id=TenantId(\"awsgraph1\"),\n",
    "\n",
    "    #post_processors=[\n",
    "    #    SentenceReranker(),\n",
    "    #    StatementDiversityPostProcessor(),\n",
    "    #    StatementEnhancementPostProcessor()\n",
    "    #]\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)\n",
    "\n"
   ],
   "id": "981a43d941d951b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 09:09:20:WARNING:g.l.s.v.pg_vector_indexes:Index statement_awsgraph1 does not exist\n",
      "I apologize, but I do not have enough information from the provided search results to accurately answer your question about the differences between Neptune Database and Neptune Analytics. The search results are empty, so I cannot make any claims or comparisons between these two services. To provide an accurate response, I would need specific information about both Neptune Database and Neptune Analytics from reliable sources.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:30:26.163191Z",
     "start_time": "2025-05-06T11:30:26.160629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure AWS Profile and Region\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "print(f\"GraphRAGConfig: {GraphRAGConfig}\")"
   ],
   "id": "bd584d2b8e0f7bd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAGConfig: _GraphRAGConfig(_aws_profile='padmin', _aws_region='us-east-1', _aws_clients={}, _extraction_llm=None, _response_llm=BedrockConverse(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x710f9bfb6810>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x71107f1aae80>, completion_to_prompt=<function default_completion_to_prompt at 0x71107f212700>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='us.anthropic.claude-3-5-sonnet-20240620-v1:0', temperature=0.0, max_tokens=4096, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, guardrail_identifier=None, guardrail_version=None, trace=None, additional_kwargs={}), _embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x710f9bfb6810>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), _embed_dimensions=1024, _reranking_model=None, _extraction_num_workers=None, _extraction_num_threads_per_worker=None, _extraction_batch_size=None, _build_num_workers=None, _build_batch_size=None, _build_batch_write_size=None, _batch_writes_enabled=None, _include_domain_labels=None, _enable_cache=False)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:08:53.638484Z",
     "start_time": "2025-05-06T13:08:53.584248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "\n",
    "# Access the global instance\n",
    "cfg = GraphRAGConfig\n",
    "\n",
    "# Override embed model\n",
    "cfg._embed_model = BedrockEmbedding(\n",
    "    model_name=\"cohere.embed-english-v3\",\n",
    "    profile_name=\"padmin\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Override response model\n",
    "cfg._response_llm = BedrockConverse(\n",
    "    model=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    profile_name=\"padmin\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "# Optional: explicitly set known dimensions and flags\n",
    "cfg._embed_dimensions = 1024\n",
    "cfg._enable_cache = False\n"
   ],
   "id": "28ff934b54f28662",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:10:03.065047Z",
     "start_time": "2025-05-06T13:09:44.603585Z"
    }
   },
   "source": [
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import RerankingBeamGraphSearch, StatementCosineSimilaritySearch, KeywordRankingSearch\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker\n",
    "from graphrag_toolkit.lexical_graph.tenant_id import TenantId\n",
    "from graphrag_toolkit.lexical_graph import set_logging_config\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = SentenceReranker(\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store,\n",
    "    vector_store,\n",
    "    retrievers=[\n",
    "        cosine_retriever,\n",
    "        keyword_retriever,\n",
    "        beam_retriever\n",
    "    ],\n",
    "    #tenant_id=TenantId(\"awsgraph1\")\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "\n",
    "print(response.response)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 09:09:45:INFO:datasets       :PyTorch version 2.7.0 available.\n",
      "2025-05-06 09:09:46:WARNING:g.l.s.v.pg_vector_indexes:Index statement_awsgraph1 does not exist\n",
      "2025-05-06 09:09:48:WARNING:g.l.s.v.pg_vector_indexes:Index statement_awsgraph1 does not exist\n",
      "2025-05-06 09:09:48:WARNING:g.l.s.v.pg_vector_indexes:Index statement_awsgraph1 does not exist\n",
      "2025-05-06 09:09:48:INFO:g.l.r.r.rerank_beam_search:Retrieved 99 new nodes through beam search.\n",
      "Neptune Database and Neptune Analytics are two distinct components of Amazon Neptune, each designed for different purposes and use cases. Here are the key differences between them:\n",
      "\n",
      "1. Purpose:\n",
      "Neptune Database is a fully managed graph database service [source_4], while Neptune Analytics is an analytics database engine specifically designed for graph analytics [source_1, source_2].\n",
      "\n",
      "2. Use Cases:\n",
      "Neptune Database is suitable for applications like fraud alerting, Customer 360, and social networking [source_1]. Neptune Analytics, on the other hand, is ideal for data science workloads, investigatory and exploratory tasks, and workloads requiring fast iteration for analytical, data, and algorithmic processing [source_2].\n",
      "\n",
      "3. Data Processing:\n",
      "Neptune Database is designed for optimal scalability and availability, capable of handling up to 100,000 queries per second [source_1]. Neptune Analytics focuses on quickly analyzing large amounts of graph data in memory, processing thousands of analytic queries per second [source_1, source_2].\n",
      "\n",
      "4. Data Storage:\n",
      "Neptune Database is a serverless graph database [source_1], while Neptune Analytics stores large graph datasets in memory for faster processing [source_2].\n",
      "\n",
      "5. Algorithms and Queries:\n",
      "Neptune Analytics provides a library of optimized graph analytic algorithms and supports low-latency graph queries [source_2]. It also offers vector search capabilities within graph traversals [source_2].\n",
      "\n",
      "6. Data Loading:\n",
      "Neptune Analytics can load data from various sources, including Neptune Database snapshots, graphs stored in Amazon S3, and directly from Neptune Database endpoints [source_2, source_3].\n",
      "\n",
      "7. Management:\n",
      "Neptune Database requires setup for database configuration, backups, and hardware provisioning [source_4]. Neptune Analytics, however, automatically provisions compute resources based on graph size and manages graphs instead of infrastructure [source_3].\n",
      "\n",
      "8. Query Language:\n",
      "Neptune Analytics uses the openCypher language for querying [source_3], while Neptune Database supports multiple graph query languages.\n",
      "\n",
      "9. Scalability:\n",
      "Neptune Database offers multi-Region deployments and Multi-AZ high availability [source_1]. Neptune Analytics focuses on in-memory processing and automatic resource provisioning for analytics workloads [source_3].\n",
      "\n",
      "In summary, Neptune Database is designed for operational graph database needs, while Neptune Analytics complements it by providing powerful analytical capabilities for large-scale graph data processing and insights [source_2, source_4].\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:05:08.198048Z",
     "start_time": "2025-05-06T13:05:08.195301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure AWS Profile and Region\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "print(f\"GraphRAGConfig: {GraphRAGConfig}\")"
   ],
   "id": "f4ad4b82408e0f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAGConfig: _GraphRAGConfig(_aws_profile='padmin', _aws_region='us-east-1', _aws_clients={}, _extraction_llm=None, _response_llm=BedrockConverse(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x72674b4a5fa0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7268317aee80>, completion_to_prompt=<function default_completion_to_prompt at 0x726831816700>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='us.anthropic.claude-3-5-sonnet-20240620-v1:0', temperature=0.0, max_tokens=4096, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, guardrail_identifier=None, guardrail_version=None, trace=None, additional_kwargs={}), _embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x72674b1fb2f0>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), _embed_dimensions=1024, _reranking_model=None, _extraction_num_workers=None, _extraction_num_threads_per_worker=None, _extraction_batch_size=None, _build_num_workers=None, _build_batch_size=None, _build_batch_write_size=None, _batch_writes_enabled=None, _include_domain_labels=None, _enable_cache=False)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:08:13.130928Z",
     "start_time": "2025-05-06T13:08:05.496830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- 1. Configure GraphRAG first ----\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "\n",
    "GraphRAGConfig._embed_model = BedrockEmbedding(\n",
    "    model_name=\"cohere.embed-english-v3\",\n",
    "    profile_name=\"padmin\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "GraphRAGConfig._embed_dimensions = 1024\n",
    "\n",
    "GraphRAGConfig._response_llm = BedrockConverse(\n",
    "    model=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    profile_name=\"padmin\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "# ---- 2. Now initialize the vector and graph stores ----\n",
    "import os\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory, GraphStoreFactory\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ[\"GRAPH_STORE\"])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ[\"VECTOR_STORE\"])\n",
    "\n",
    "# ---- 3. Setup logging ----\n",
    "from graphrag_toolkit.lexical_graph import set_logging_config\n",
    "set_logging_config(\"INFO\")\n",
    "\n",
    "# ---- 4. Create retrievers ----\n",
    "from graphrag_toolkit.lexical_graph.retrieval.retrievers import (\n",
    "    RerankingBeamGraphSearch,\n",
    "    StatementCosineSimilaritySearch,\n",
    "    KeywordRankingSearch\n",
    ")\n",
    "from graphrag_toolkit.lexical_graph.retrieval.post_processors import SentenceReranker\n",
    "\n",
    "cosine_retriever = StatementCosineSimilaritySearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "keyword_retriever = KeywordRankingSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    max_keywords=10\n",
    ")\n",
    "\n",
    "reranker = SentenceReranker(batch_size=128)\n",
    "\n",
    "beam_retriever = RerankingBeamGraphSearch(\n",
    "    vector_store=vector_store,\n",
    "    graph_store=graph_store,\n",
    "    reranker=reranker,\n",
    "    initial_retrievers=[cosine_retriever, keyword_retriever],\n",
    "    max_depth=8,\n",
    "    beam_width=100\n",
    ")\n",
    "\n",
    "# ---- 5. Initialize query engine ----\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "\n",
    "query_engine = LexicalGraphQueryEngine.for_semantic_guided_search(\n",
    "    graph_store,\n",
    "    vector_store,\n",
    "    retrievers=[cosine_retriever, keyword_retriever, beam_retriever]\n",
    "    # You can enable multi-tenancy with: tenant_id=TenantId(\"awsgraph1\")\n",
    ")\n",
    "\n",
    "# ---- 6. Run the query ----\n",
    "response = query_engine.query(\"What are the differences between Neptune Database and Neptune Analytics?\")\n",
    "print(response.response)\n"
   ],
   "id": "ad8240cf621797d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evanerwee/anaconda3/envs/graphrag-toolkit4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 09:08:06:INFO:datasets       :PyTorch version 2.7.0 available.\n",
      "I apologize, but I do not have enough information from the provided search results to accurately answer your question about the differences between Neptune Database and Neptune Analytics. The search results are empty, so I cannot make any factual statements or comparisons between these two services. To provide a proper answer, I would need specific information about the features, capabilities, and use cases of both Neptune Database and Neptune Analytics.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:08:14.696038Z",
     "start_time": "2025-05-06T13:08:14.693623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure AWS Profile and Region\n",
    "from graphrag_toolkit.lexical_graph import GraphRAGConfig\n",
    "print(f\"GraphRAGConfig: {GraphRAGConfig}\")"
   ],
   "id": "16c3bb46efc59a61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAGConfig: _GraphRAGConfig(_aws_profile='padmin', _aws_region='us-east-1', _aws_clients={}, _extraction_llm=None, _response_llm=BedrockConverse(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x71df0ae6c830>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x71dff1186de0>, completion_to_prompt=<function default_completion_to_prompt at 0x71dff11ee660>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='us.anthropic.claude-3-5-sonnet-20240620-v1:0', temperature=0.0, max_tokens=4096, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, guardrail_identifier=None, guardrail_version=None, trace=None, additional_kwargs={}), _embed_model=BedrockEmbedding(model_name='cohere.embed-english-v3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x71df0ad9bfb0>, num_workers=None, profile_name='padmin', aws_access_key_id=None, aws_secret_access_key=None, aws_session_token=None, region_name='us-east-1', botocore_session=None, botocore_config=None, max_retries=10, timeout=60.0, additional_kwargs={}), _embed_dimensions=1024, _reranking_model=None, _extraction_num_workers=None, _extraction_num_threads_per_worker=None, _extraction_batch_size=None, _build_num_workers=None, _build_batch_size=None, _build_batch_write_size=None, _batch_writes_enabled=None, _include_domain_labels=None, _enable_cache=False)\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
